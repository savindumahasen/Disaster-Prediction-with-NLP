{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140e0081-2670-429b-9ce2-cdfe638f71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d89d0e-f176-43ca-b8f0-3204051e2ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset =pd.read_csv(\"train.csv\", encoding=\"ISO-8859-1\")\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15cdbc2-36c7-44ff-afc1-9986043da77c",
   "metadata": {},
   "source": [
    "## Explotary Data Analaysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d69ff-5bef-4b0c-9669-c1c9beff27b5",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecc73b0f-7afc-460f-af6a-0df1ac4deb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the information about the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2cf2ae-f610-4a1d-a62e-284c788d7881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db29e917-6093-4733-9f65-7b9fb133d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the duplicated entries of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fca957e-a8a9-4d57-879f-2d284d6dd1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31670778-83cd-454e-9339-8853de1dfb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the value counts of keyword column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92dabab3-406c-4942-b468-039af9909dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword\n",
       "fatalities               45\n",
       "deluge                   42\n",
       "armageddon               42\n",
       "sinking                  41\n",
       "damage                   41\n",
       "                         ..\n",
       "forest%20fire            19\n",
       "epicentre                12\n",
       "threat                   11\n",
       "inundation               10\n",
       "radiation%20emergency     9\n",
       "Name: count, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b17e0869-c04a-469f-9dfb-e50207364b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the value counts of location column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c664d5ad-3057-4497-a986-cfacd0e215ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "USA                    104\n",
       "New York                71\n",
       "United States           50\n",
       "London                  45\n",
       "Canada                  29\n",
       "                      ... \n",
       "MontrÌ©al, QuÌ©bec       1\n",
       "Montreal                 1\n",
       "ÌÏT: 6.4682,3.18287      1\n",
       "Live4Heed??              1\n",
       "Lincoln                  1\n",
       "Name: count, Length: 3341, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41b55882-1eb1-4846-b841-41a3c0418c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "1       NaN\n",
       "2       NaN\n",
       "3       NaN\n",
       "4       NaN\n",
       "       ... \n",
       "7608    NaN\n",
       "7609    NaN\n",
       "7610    NaN\n",
       "7611    NaN\n",
       "7612    NaN\n",
       "Name: location, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d9f775d-abb5-4256-975d-853700bef327",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the null values of the keyword column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c22616d-c30b-4469-9101-d007867f0675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['keyword'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ece034cd-006c-404e-a66d-ae8611923d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the null values of the location column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdbb03b2-d6e2-4ca9-82b2-ba6f5f98ee31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2533"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['location'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b5326b4-f095-406a-a568-53afa429bd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill the nul values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bc4c1fc-c254-4433-886b-f687643ce785",
   "metadata": {},
   "outputs": [],
   "source": [
    " train_dataset['location'].fillna('Canada', inplace=True)\n",
    " train_dataset['keyword'].fillna('radiation%20emergency', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01e277a8-77eb-42da-a74a-e4c6dc47bae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>radiation%20emergency</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>radiation%20emergency</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>radiation%20emergency</td>\n",
       "      <td>Canada</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>radiation%20emergency</td>\n",
       "      <td>Canada</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>radiation%20emergency</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                keyword location  \\\n",
       "0   1  radiation%20emergency   Canada   \n",
       "1   4  radiation%20emergency   Canada   \n",
       "2   5  radiation%20emergency   Canada   \n",
       "3   6  radiation%20emergency   Canada   \n",
       "4   7  radiation%20emergency   Canada   \n",
       "\n",
       "                                                text  target  \n",
       "0  Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1             Forest fire near La Ronge Sask. Canada       1  \n",
       "2  All residents asked to 'shelter in place' are ...       1  \n",
       "3  13,000 people receive #wildfires evacuation or...       1  \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84b79b5b-6277-4bad-a9de-ec7aeb10bbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7613 non-null   object\n",
      " 2   location  7613 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b96b85-72c1-46fd-a925-2b2c4f2de2b9",
   "metadata": {},
   "source": [
    "#### Text Preprcoessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b011c561-0819-4996-900b-436d0d918d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "980806ba-4108-41ef-b768-83684fa5ce9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our Deeds are the Reason of this #earthquake M...\n",
       "1               Forest fire near La Ronge Sask. Canada\n",
       "2    All residents asked to 'shelter in place' are ...\n",
       "3    13,000 people receive #wildfires evacuation or...\n",
       "4    Just got sent this photo from Ruby #Alaska as ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bd54e66-1fe3-4782-8558-97b49f8b4d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    radiation%20emergency\n",
       "1    radiation%20emergency\n",
       "2    radiation%20emergency\n",
       "3    radiation%20emergency\n",
       "4    radiation%20emergency\n",
       "Name: keyword, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['keyword'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed9fc8bc-2566-4e65-a6e8-0a41d11bbde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Canada\n",
       "1    Canada\n",
       "2    Canada\n",
       "3    Canada\n",
       "4    Canada\n",
       "Name: location, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['location'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d76e46e-f31b-47c8-aab9-6e6ac0b6a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the uppercase letters into the lowercase letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "091650f8-2df0-4f65-ab1d-926565ae1796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       our deeds are the reason of this #earthquake m...\n",
       "1                  forest fire near la ronge sask. canada\n",
       "2       all residents asked to 'shelter in place' are ...\n",
       "3       13,000 people receive #wildfires evacuation or...\n",
       "4       just got sent this photo from ruby #alaska as ...\n",
       "                              ...                        \n",
       "7608    two giant cranes holding a bridge collapse int...\n",
       "7609    @aria_ahrary @thetawniest the out of control w...\n",
       "7610    m1.94 [01:04 utc]?5km s of volcano hawaii. htt...\n",
       "7611    police investigating after an e-bike collided ...\n",
       "7612    the latest: more homes razed by northern calif...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['text'] = train_dataset['text'].apply(lambda x:\" \".join(x.lower() for x in x.split()))\n",
    "train_dataset['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a66028d6-b9d3-4bfe-80cf-51fff1063cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100                         uk\n",
       "101             nairobi, kenya\n",
       "102    instagram - @heyimginog\n",
       "103                        304\n",
       "104                switzerland\n",
       "                ...           \n",
       "195        || c h i c a g o ||\n",
       "196                     canada\n",
       "197                      l. a.\n",
       "198                     canada\n",
       "199                     canada\n",
       "Name: location, Length: 100, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['location']=train_dataset['location'].apply(lambda x:\" \".join(x.lower() for x in x.split()))\n",
    "train_dataset['location'].iloc[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2034f617-85f8-4e90-a95b-e30ce82eafe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccbcfb81-0bd0-49b1-a1c9-53a9c47e80a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    our deeds are the reason of this #earthquake m...\n",
       "1               forest fire near la ronge sask. canada\n",
       "2    all residents asked to 'shelter in place' are ...\n",
       "3    13,000 people receive #wildfires evacuation or...\n",
       "4    just got sent this photo from ruby #alaska as ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['text']=train_dataset['text'].apply(lambda x: \" \".join(re.sub(r'^https?:\\/\\/.*[\\r\\n]*','',x,flags=re.MULTILINE) for x in x.split()))\n",
    "train_dataset['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcde335b-742f-4dd5-a4aa-edc9a551234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb0cfdd9-b56d-483b-a5b2-22d3b924ddeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb7e19e9-14db-4664-9083-e216f96aeca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_puncutations_of_text(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text=text.replace(punctuation, '')\n",
    "    return text\n",
    "train_dataset['text']=train_dataset['text'].apply(remove_puncutations_of_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d0ef4ea-ab62-42c2-a6dd-60c00190d489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    our deeds are the reason of this earthquake ma...\n",
       "1                forest fire near la ronge sask canada\n",
       "2    all residents asked to shelter in place are be...\n",
       "3    13000 people receive wildfires evacuation orde...\n",
       "4    just got sent this photo from ruby alaska as s...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fb06cde-f85e-4c8c-8a90-4a6effbf84ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations_of_location(text):\n",
    "    for punctuations in string.punctuation:\n",
    "        location=text.replace(punctuations,'')\n",
    "    return location\n",
    "train_dataset['location']=train_dataset['location'].apply(remove_punctuations_of_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38ff0755-637b-4738-8515-e265ea8bc110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    canada\n",
       "1    canada\n",
       "2    canada\n",
       "3    canada\n",
       "4    canada\n",
       "Name: location, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['location'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97178919-8190-4b30-82ca-27e4daa99647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations_of_keyword(text):\n",
    "    for punctuations in string.punctuation:\n",
    "        keyword=text.replace(punctuations,'')\n",
    "    return keyword\n",
    "train_dataset['keyword']=train_dataset['keyword'].apply(remove_punctuations_of_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92e93b50-eb1d-43bf-ba53-8dc63a9058e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    radiation%20emergency\n",
       "1    radiation%20emergency\n",
       "2    radiation%20emergency\n",
       "3    radiation%20emergency\n",
       "4    radiation%20emergency\n",
       "Name: keyword, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['keyword'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ceeb15e4-22d1-4577-b549-51cf55976aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6831d0f1-7c2a-4e28-8ba6-fcbd53bd1591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\THIS PC\\AppData\\Local\\Temp\\ipykernel_14140\\4125517438.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  train_dataset['text']=train_dataset['text'].str.replace('\\d+','',regex=True)\n"
     ]
    }
   ],
   "source": [
    "train_dataset['text']=train_dataset['text'].str.replace('\\d+','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "968a4cd8-4905-4ab9-bcc8-ec413966f4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    our deeds are the reason of this earthquake ma...\n",
       "1                forest fire near la ronge sask canada\n",
       "2    all residents asked to shelter in place are be...\n",
       "3     people receive wildfires evacuation orders in...\n",
       "4    just got sent this photo from ruby alaska as s...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e821313-0858-40aa-a360-cd3f27b46c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\THIS PC\\AppData\\Local\\Temp\\ipykernel_14140\\3033268000.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  train_dataset['keyword']=train_dataset['keyword'].str.replace('\\d+','',regex=True)\n"
     ]
    }
   ],
   "source": [
    "train_dataset['keyword']=train_dataset['keyword'].str.replace('\\d+','',regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ec3a6b1-e459-443f-999f-963be6a55e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    radiation%emergency\n",
       "1    radiation%emergency\n",
       "2    radiation%emergency\n",
       "3    radiation%emergency\n",
       "4    radiation%emergency\n",
       "Name: keyword, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['keyword'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0c4d365-8cbf-4968-9fef-587e1663c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f867095-5fed-4696-ab06-f87e099358b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32ca489d-072d-4a3d-9c7c-dac31ee8c7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to static/model...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords', download_dir=\"static/model\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ebd27bc0-3566-48aa-894e-84bf6b0175c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./static/model/corpora/stopwords/english', 'r') as file:\n",
    "    sw =file.read().splitlines()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04c88285-e14a-4fec-8927-bb3ea95fa2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ed74c4f-6253-49d0-b0e2-b2dce0e4217b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         deeds reason earthquake may allah forgive us\n",
       "1                forest fire near la ronge sask canada\n",
       "2    residents asked shelter place notified officer...\n",
       "3    people receive wildfires evacuation orders cal...\n",
       "4    got sent photo ruby alaska smoke wildfires pou...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['text']=train_dataset['text'].apply(lambda x:\" \".join(x for x in x.split() if x not in sw))\n",
    "train_dataset['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5e513d4-13ef-4a73-a69c-b506b1a7fd04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    radiation%emergency\n",
       "1    radiation%emergency\n",
       "2    radiation%emergency\n",
       "3    radiation%emergency\n",
       "4    radiation%emergency\n",
       "Name: keyword, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['keyword']=train_dataset['keyword'].apply(lambda x:\" \".join(x for x in x.split() if x not in sw))\n",
    "train_dataset['keyword'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "529dd342-f7d4-42be-ada1-072f4d5e3bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stemming technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b4ef66f-76da-4403-a94f-207b50bc3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abe04b8d-834f-4623-b78b-138af3e8481c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            deed reason earthquak may allah forgiv us\n",
       "1                 forest fire near la rong sask canada\n",
       "2    resid ask shelter place notifi offic evacu she...\n",
       "3          peopl receiv wildfir evacu order california\n",
       "4    got sent photo rubi alaska smoke wildfir pour ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['text']=train_dataset['text'].apply(lambda x:\" \".join(ps.stem(x) for x in x.split()))\n",
    "train_dataset['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35d029ac-6111-432d-8bd3-8ac8446bc4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    radiation%emerg\n",
       "1    radiation%emerg\n",
       "2    radiation%emerg\n",
       "3    radiation%emerg\n",
       "4    radiation%emerg\n",
       "Name: keyword, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['keyword']=train_dataset['keyword'].apply(lambda x:\" \".join(ps.stem(x) for x in x.split()))\n",
    "train_dataset['keyword'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02b7fbba-a4bd-4dc4-a2bd-f14557d7908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## print the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5efe8f5-0c32-48d0-8150-341ab5671609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>deed reason earthquak may allah forgiv us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir pour ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          keyword location  \\\n",
       "0   1  radiation%emerg   canada   \n",
       "1   4  radiation%emerg   canada   \n",
       "2   5  radiation%emerg   canada   \n",
       "3   6  radiation%emerg   canada   \n",
       "4   7  radiation%emerg   canada   \n",
       "\n",
       "                                                text  target  \n",
       "0          deed reason earthquak may allah forgiv us       1  \n",
       "1               forest fire near la rong sask canada       1  \n",
       "2  resid ask shelter place notifi offic evacu she...       1  \n",
       "3        peopl receiv wildfir evacu order california       1  \n",
       "4  got sent photo rubi alaska smoke wildfir pour ...       1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84c09eee-571e-4491-a382-31f23507c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "646575b2-2dc4-4ee6-a607-cd47cd413290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "vocab=Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf93a165-9802-41c5-aca6-1d6c3c837c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "61219255-57f8-406d-a6b1-6737823a1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in train_dataset['text']:\n",
    "    vocab.update(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4382a943-30a7-4cea-8cf3-380f4d462040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14091"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "894a2702-834f-4f11-8d69-6dd1e520d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "for words in train_dataset['keyword']:\n",
    "    vocab.update(words.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cb1a24dd-7e16-4e92-802b-965a92d91672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14122"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d75de53-297e-4844-9a59-9a763817d619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14122"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2ec5630-dd2e-4059-b6b8-66c57d163502",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [key for key in vocab if vocab[key]>10 and vocab[key]<75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a952be7-5fde-40d7-9842-f23e1d9c7a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1148"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f537ba7-a71d-4128-87f3-26c358fb025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "898718e5-fbbf-4887-8706-ff2af13507d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vocabulary(lines, file_path):\n",
    "    data = '\\n'.join(lines)\n",
    "    file=open(file_path, 'w', encoding=\"utf-8\")\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "save_vocabulary(tokens, \"./static/model/vocabulary.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9b4b571-b254-493c-91a5-b1d0283777de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a7d6334e-195a-4dc4-854e-8848345a8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train_dataset.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8a1bf172-531b-4d6f-a2b7-224771891870",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train_dataset.drop({'id','target'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5d092b62-8a26-48e1-82da-54a2ab3c40e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>deed reason earthquak may allah forgiv us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>resid ask shelter place notifi offic evacu she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>peopl receiv wildfir evacu order california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>got sent photo rubi alaska smoke wildfir pour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>two giant crane hold bridg collaps nearbi home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>ariaahrari thetawniest control wild fire calif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>utckm volcano hawaii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>polic investig ebik collid car littl portug eb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>radiation%emerg</td>\n",
       "      <td>canada</td>\n",
       "      <td>latest home raze northern california wildfir a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              keyword location  \\\n",
       "0     radiation%emerg   canada   \n",
       "1     radiation%emerg   canada   \n",
       "2     radiation%emerg   canada   \n",
       "3     radiation%emerg   canada   \n",
       "4     radiation%emerg   canada   \n",
       "...               ...      ...   \n",
       "7608  radiation%emerg   canada   \n",
       "7609  radiation%emerg   canada   \n",
       "7610  radiation%emerg   canada   \n",
       "7611  radiation%emerg   canada   \n",
       "7612  radiation%emerg   canada   \n",
       "\n",
       "                                                   text  \n",
       "0             deed reason earthquak may allah forgiv us  \n",
       "1                  forest fire near la rong sask canada  \n",
       "2     resid ask shelter place notifi offic evacu she...  \n",
       "3           peopl receiv wildfir evacu order california  \n",
       "4     got sent photo rubi alaska smoke wildfir pour ...  \n",
       "...                                                 ...  \n",
       "7608     two giant crane hold bridg collaps nearbi home  \n",
       "7609  ariaahrari thetawniest control wild fire calif...  \n",
       "7610                               utckm volcano hawaii  \n",
       "7611  polic investig ebik collid car littl portug eb...  \n",
       "7612  latest home raze northern california wildfir a...  \n",
       "\n",
       "[7613 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3e88616e-53f5-46f0-8e3e-35dadacfa613",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train_dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "85b7bb98-7c7c-48fe-96dd-5b40d168c8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "7608    1\n",
       "7609    1\n",
       "7610    1\n",
       "7611    1\n",
       "7612    1\n",
       "Name: target, Length: 7613, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a1ec6103-b536-411a-adf7-628b1d5e48b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "19badf05-3d6d-41fb-95ee-837169f00e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090, 3)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "71d9f32a-ea4b-4a1f-924f-e99cd1e63853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090,)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e019218c-3fd9-4b3d-90f9-978e30022510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1523, 3)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "13f2148a-1590-4624-a571-0bbac3a7f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conver the text into  numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fb573fdd-d041-47e1-b6ba-b7bf1d8bbd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6166770f-88c4-4f94-a7fa-d1d5c16f5b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090,)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "09690565-cc12-40e0-9ba1-caf20ec5e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorizer(ds, vocabulary):\n",
    "    vectorizer_list = []\n",
    "    vocab_set = set(vocabulary)  # Use a set for faster lookup\n",
    "    \n",
    "    for sentence in ds:\n",
    "        sentence_list = np.zeros(len(vocabulary), dtype=np.float16)  # Use np.float16 to reduce memory usage\n",
    "        sentence_words = set(sentence.split())  # Split and convert sentence to a set to speed up membership checking\n",
    "        \n",
    "        for i, word in enumerate(vocabulary):\n",
    "            if word in sentence_words:  # Check if word exists in the sentence\n",
    "                sentence_list[i] = 1\n",
    "                \n",
    "        vectorizer_list.append(sentence_list)\n",
    "    \n",
    "    # Convert the list to a numpy array only once\n",
    "    vectorizer_list_new = np.asarray(vectorizer_list, dtype=np.float16)\n",
    "    \n",
    "    return vectorizer_list_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "48ae7225-61b0-486d-aaa7-de0f333ed66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorizer(ds, vocabulary):\n",
    "    vectorizer_list = []\n",
    "    vocab_set=set(vocabulary)\n",
    "    for sentence in ds:\n",
    "        sentence_list = np.zeros(len(vocabulary), dtype=np.float16)  # Create a zero array for each sentence\n",
    "        sentence_words = set(sentence.split())  # Convert the sentence into a set of words\n",
    "        \n",
    "        for i, word in enumerate(vocabulary):  # Iterate over the vocabulary (list, ordered)\n",
    "            if word in sentence_words:  # Check if the word exists in the sentence\n",
    "                sentence_list[i] = 1  # Set the corresponding index to 1\n",
    "                \n",
    "        vectorizer_list.append(sentence_list)\n",
    "    \n",
    "    # Convert the list of arrays to a numpy array\n",
    "    vectorizer_list_new = np.asarray(vectorizer_list, dtype=np.float16)\n",
    "    \n",
    "    return vectorizer_list_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "832b98a0-0ac6-4eb4-a9ee-c3c37f1e7f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_x_train= vectorizer(x_train['text'], tokens)\n",
    "vectorizer_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "72ac4d11-d785-4a87-9594-c211b8047a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_x_train=vectorizer(x_train['location'],tokens)\n",
    "vectorizer_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9e2c2e1a-2fb6-4c29-a6bf-418afbec50f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_x_train=vectorizer(x_train['keyword'],tokens)\n",
    "vectorizer_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1e8a8ba6-fad7-4194-a04d-872214bb7405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_x_test=vectorizer(x_test['text'],tokens)\n",
    "vectorizer_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "dd0b3a50-b7f0-42d2-baa2-e020d9fede24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_x_test=vectorizer(x_test['location'],tokens)\n",
    "vectorizer_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2d1ea02a-8b34-4d3a-bfb9-c89f7ec8d508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_x_test=vectorizer(x_test['keyword'],tokens)\n",
    "vectorizer_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "77eff753-0854-486c-b29f-503b33e5a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the vlue of counts of y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "730e2dfb-e999-469b-8864-dc09ebb29fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    3468\n",
       "1    2622\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b06757ea-98f0-4df6-8d53-e945fe1f1bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090, 1148)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "05d79d4b-49bd-45cd-b8a3-779b710b5a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090,)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fd557e1c-0d23-40a0-9c41-ef34e828f2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1523, 1148)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "375f3d94-0351-4c6e-96aa-038cc662ac0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1138</th>\n",
       "      <th>1139</th>\n",
       "      <th>1140</th>\n",
       "      <th>1141</th>\n",
       "      <th>1142</th>\n",
       "      <th>1143</th>\n",
       "      <th>1144</th>\n",
       "      <th>1145</th>\n",
       "      <th>1146</th>\n",
       "      <th>1147</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6090 rows × 1148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  1138  \\\n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "6085   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "6086   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "6087   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "6088   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "6089   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "      1139  1140  1141  1142  1143  1144  1145  1146  1147  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "6085   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "6086   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "6087   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "6088   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "6089   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[6090 rows x 1148 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_x_train_pd = pd.DataFrame(vectorizer_x_train)\n",
    "vectorizer_x_train_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "600a20af-6827-40ee-8e7d-9ee582fcd1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix the imbalance data issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7724a1-b831-4378-ba8f-85f8f2384281",
   "metadata": {},
   "source": [
    "##  Model Selectiona And Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5498a60f-cc95-4a45-b906-b7c632131641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4d08ca6d-7010-4e51-b4e9-d2c77ae4d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## logistci regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "57923211-e5f2-456f-9275-2a713f1db05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr=LogisticRegression()\n",
    "#lr.fit(vectorizer_x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b0f7923d-8731-4f22-abfe-e6db067688ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6349310571240971"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lr_predictions = lr.predict(vectorizer_x_test)\n",
    "#accuracy_score(y_test,lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae251dc-08db-4868-853f-b99c4d4c7e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
